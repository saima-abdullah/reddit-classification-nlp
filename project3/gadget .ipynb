{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5eb40ff-ce43-45e0-91a2-5cb2623afaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting posts from r/technology in category 'new'...\n",
      "Collecting posts from r/technology in category 'hot'...\n",
      "Collecting posts from r/gadgets in category 'new'...\n",
      "Collecting posts from r/gadgets in category 'hot'...\n",
      "                                               title content  \\\n",
      "0  Brightness of first Chinese broadband constell...           \n",
      "1  Collapse of national security elites’ cyber fi...           \n",
      "2  Teens already on social media could be exempt ...           \n",
      "3  License Plate Readers Are Creating a US-Wide D...           \n",
      "4  Japan’s tokamak sets world record, achieves pl...           \n",
      "\n",
      "            timestamp   subreddit category  \n",
      "0 2024-10-06 05:25:43  technology      new  \n",
      "1 2024-10-06 04:46:03  technology      new  \n",
      "2 2024-10-06 03:55:20  technology      new  \n",
      "3 2024-10-06 03:18:42  technology      new  \n",
      "4 2024-10-06 02:28:05  technology      new  \n",
      "Total unique posts: 1661\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Reddit API credentials\n",
    "client_id = 'Nrbc6n5KVQ6fEQ_7JUfH3A'\n",
    "client_secret = 'Y0STrnfxdJh_r5h9TS5qxx2tAs5swg'\n",
    "username = 'Important_Trade_7759'\n",
    "password = 'saima123'\n",
    "user_agent = 'data'\n",
    "\n",
    "# Authentication with Reddit API\n",
    "auth = requests.auth.HTTPBasicAuth(client_id, client_secret)\n",
    "data = {'grant_type': 'password', 'username': username, 'password': password}\n",
    "headers = {'User-Agent': user_agent}\n",
    "\n",
    "res = requests.post('https://www.reddit.com/api/v1/access_token', auth=auth, data=data, headers=headers)\n",
    "token = res.json()['access_token']\n",
    "headers['Authorization'] = f'bearer {token}'\n",
    "\n",
    "# Generalized function to fetch data from Reddit\n",
    "def fetch_data(url, params=None):\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Failed to fetch data from {url}: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Function to collect posts from a subreddit with pagination\n",
    "def collect_posts_by_category(subreddit, category, limit=1000):\n",
    "    posts = []\n",
    "    after = None  # To keep track of pagination\n",
    "    collected_posts = 0  # Counter for posts collected so far\n",
    "\n",
    "    # Set the correct endpoint based on the category\n",
    "    url = f'https://oauth.reddit.com/r/{subreddit}/{category}'\n",
    "\n",
    "    while collected_posts < limit:\n",
    "        params = {'limit': 100}  # Max limit per request\n",
    "        if after:\n",
    "            params['after'] = after\n",
    "\n",
    "        data = fetch_data(url, params)\n",
    "\n",
    "        if data and 'data' in data:\n",
    "            for post in data['data']['children']:\n",
    "                post_id = post['data']['id']\n",
    "                post_title = post['data']['title']\n",
    "                post_content = post['data']['selftext']\n",
    "                post_created_utc = post['data']['created_utc']\n",
    "                post_subreddit = subreddit\n",
    "\n",
    "                posts.append([post_title, post_content, post_created_utc, post_subreddit, category])\n",
    "                collected_posts += 1\n",
    "\n",
    "                # Stop if we reach the desired limit\n",
    "                if collected_posts >= limit:\n",
    "                    break\n",
    "\n",
    "            # Update 'after' for pagination\n",
    "            after = data['data']['after']\n",
    "            if not after:  # No more posts to fetch\n",
    "                break\n",
    "\n",
    "            # Add a delay to avoid hitting rate limits\n",
    "            time.sleep(2)  # Sleep for 2 seconds between requests\n",
    "\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return posts[:limit]  # Return only up to the specified limit\n",
    "\n",
    "# Function to collect posts for multiple subreddits and categories\n",
    "def collect_posts_for_subreddits(subreddits, categories, limit_per_category=1000):\n",
    "    all_posts = []\n",
    "    for subreddit in subreddits:\n",
    "        for category in categories:\n",
    "            print(f\"Collecting posts from r/{subreddit} in category '{category}'...\")\n",
    "            posts = collect_posts_by_category(subreddit, category, limit_per_category)\n",
    "            all_posts.extend(posts)\n",
    "    return all_posts\n",
    "\n",
    "# List of subreddits and categories to collect data from\n",
    "subreddits_to_collect = ['technology', 'gadgets']\n",
    "categories_to_collect = ['new', 'hot']\n",
    "\n",
    "# Collect data from specified subreddits and categories\n",
    "all_posts = collect_posts_for_subreddits(subreddits_to_collect, categories_to_collect, limit_per_category=1100)\n",
    "\n",
    "# Create DataFrame\n",
    "columns = ['title', 'content', 'timestamp', 'subreddit', 'category']\n",
    "df_combined = pd.DataFrame(all_posts, columns=columns)\n",
    "\n",
    "# Convert timestamp to datetime\n",
    "df_combined['timestamp'] = pd.to_datetime(df_combined['timestamp'], unit='s')\n",
    "\n",
    "# Check for unique posts based on 'title', 'content', and 'timestamp'\n",
    "df_unique = df_combined.drop_duplicates(subset=['title', 'content', 'timestamp'])\n",
    "\n",
    "# Save the unique DataFrame to a CSV file\n",
    "df_unique.to_csv('./data/reddit_posts_new_hot.csv', index=False)\n",
    "\n",
    "# Output the unique DataFrame (for checking)\n",
    "print(df_unique.head())\n",
    "print(f\"Total unique posts: {df_unique.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62be6cf0-882b-42fb-a025-334c3e72b087",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
