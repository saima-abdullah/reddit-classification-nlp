{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd4d7cf1-6fdb-40ab-b53c-8db004e8c1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n",
      " ········\n",
      " ········\n",
      " ········\n",
      " ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "Total posts collected: 3318\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import getpass\n",
    "import os\n",
    "'''\n",
    "client_id = 'Nrbc6n5KVQ6fEQ_7JUfH3A'\n",
    "client_secret = 'Y0STrnfxdJh_r5h9TS5qxx2tAs5swg'#alphanumeric string provided as \"secret\"\n",
    "user_agent = 'data' #the name of your application\n",
    "username =  'Important_Trade_7759'#your reddit username\n",
    "password = 'saima123'\n",
    "'''\n",
    "client_id = getpass.getpass()#alphanumeric string provided under \"personal use script\"\n",
    "client_secret = getpass.getpass() #alphanumeric string provided as \"secret\"\n",
    "user_agent = getpass.getpass() #the name of your application\n",
    "username =  getpass.getpass()#your reddit username\n",
    "password =  getpass.getpass()#your reddit password'''\n",
    "\n",
    "auth = requests.auth.HTTPBasicAuth(client_id, client_secret)\n",
    "data = {\n",
    "    'grant_type': 'password',\n",
    "    'username': username,\n",
    "    'password': password\n",
    "}\n",
    "\n",
    "#create an informative header for your application\n",
    "headers = {'User-Agent': 'subreddit_data1/0.0.1'}\n",
    "res = requests.post(\n",
    "    'https://www.reddit.com/api/v1/access_token',\n",
    "    auth=auth,\n",
    "    data=data,\n",
    "    headers=headers)\n",
    "\n",
    "print(res)\n",
    "res.json()\n",
    "\n",
    "#retrieve access token\n",
    "token = res.json()['access_token']\n",
    "\n",
    "headers['Authorization'] = f'bearer {token}'\n",
    "\n",
    "requests.get('https://oauth.reddit.com/api/v1/me', headers=headers).status_code == 200\n",
    "# Generalized function to fetch posts from any category\n",
    "def fetch_posts(subreddit, category, after=None, limit=100):\n",
    "    url = f\"https://www.reddit.com/r/{subreddit}/{category}.json\"  # Dynamic category\n",
    "    headers = {'User-Agent': 'your_user_agent'}\n",
    "    params = {\n",
    "        'limit': limit,  # Max 100 posts per request\n",
    "        'after': after   # Pagination token\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Failed to fetch posts: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Function to get unique posts and return as DataFrame\n",
    "def get_unique_posts_dataframe(subreddit, category):\n",
    "    '''\n",
    "    '''\n",
    "    posts_data = []\n",
    "    unique_ids = set()  # Set to store unique post IDs\n",
    "    max_posts = 1000  # Limit for fetching\n",
    "    total_posts = 0\n",
    "    after = None\n",
    "\n",
    "    while total_posts < max_posts:\n",
    "        data = fetch_posts(subreddit, category, after)\n",
    "        if data is None:\n",
    "            break  # Stop fetching if there's an error\n",
    "\n",
    "        posts = data['data']['children']\n",
    "\n",
    "        # Extract title, assign subreddit, and category, ensuring uniqueness by ID\n",
    "        for post in posts:\n",
    "            post_id = post['data']['id']\n",
    "            if post_id not in unique_ids:\n",
    "                unique_ids.add(post_id)\n",
    "                posts_data.append({\n",
    "                    'title': post['data']['title'],\n",
    "                    'subreddit': subreddit,\n",
    "                    'category': category\n",
    "                })\n",
    "                total_posts += 1\n",
    "\n",
    "            if total_posts >= max_posts:\n",
    "                break\n",
    "\n",
    "        after = data['data']['after']  # Get the next \"after\" token\n",
    "        if after is None:\n",
    "            break  # No more posts to fetch\n",
    "\n",
    "        time.sleep(1)  # Avoid hitting Reddit API rate limits\n",
    "\n",
    "    # Convert collected posts to DataFrame\n",
    "    return pd.DataFrame(posts_data)\n",
    "\n",
    "# Ensure data directory exists\n",
    "if not os.path.exists('./data'):\n",
    "    os.makedirs('./data')\n",
    "\n",
    "# General function to fetch posts from subreddits and categories\n",
    "def fetch_and_save_posts(subreddit, categories, filename):\n",
    "    '''\n",
    "    '''\n",
    "    df_list = []\n",
    "    \n",
    "    for category in categories:\n",
    "        df_posts = get_unique_posts_dataframe(subreddit, category)\n",
    "        df_list.append(df_posts)\n",
    "    \n",
    "    df_combined = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "    # Save to CSV, if file doesn't exist, create it; if it exists, append\n",
    "    if not os.path.exists(filename):\n",
    "        df_combined.to_csv(filename, index=False)\n",
    "    else:\n",
    "        df_combined.to_csv(filename, mode='a', header=False, index=False)\n",
    "\n",
    "# Fetch posts from \"gadgets\" and \"technology\" subreddits\n",
    "subreddit_list = ['gadgets', 'technology']\n",
    "categories = ['new']\n",
    "\n",
    "for subreddit in subreddit_list:\n",
    "    fetch_and_save_posts(subreddit, categories, './data/dataframe.csv')\n",
    "\n",
    "# Display the final shape of the DataFrame\n",
    "df = pd.read_csv('./data/dataframe.csv')\n",
    "print(f\"Total posts collected: {df.shape[0]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ae58bd-4ebb-4fa0-b771-06ed260982e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "<Response [200]>\n",
    "Total posts collected: 1657"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
